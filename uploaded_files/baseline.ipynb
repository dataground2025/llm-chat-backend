{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "158ca50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from easydict import EasyDict\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53d99cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b32814b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.backends.mps.is_available())  # True여야 MPS 지원됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "822f7120",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = EasyDict()\n",
    "config.root = './data'\n",
    "config.train_path = os.path.join(config.root, 'train.csv')\n",
    "config.test_path = os.path.join(config.root, 'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4f0af3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(config.train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f1671f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7351, 9)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b58a6066",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>sentence_0</th>\n",
       "      <th>sentence_1</th>\n",
       "      <th>sentence_2</th>\n",
       "      <th>sentence_3</th>\n",
       "      <th>answer_0</th>\n",
       "      <th>answer_1</th>\n",
       "      <th>answer_2</th>\n",
       "      <th>answer_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRAIN_0000</td>\n",
       "      <td>블록체인 기술은 투표 과정의 투명성을 크게 향상시킬 수 있다.</td>\n",
       "      <td>이러한 특성은 유권자들에게 신뢰를 제공하며, 민주적 참여를 촉진하는 데 기여할 수 있다.</td>\n",
       "      <td>결과적으로 블록체인 기반의 투표 시스템은 공정하고 신뢰할 수 있는 선거 환경을 조성...</td>\n",
       "      <td>각 투표는 변경 불가능한 기록으로 저장되어 조작의 가능성을 원천적으로 차단한다.</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID                          sentence_0  \\\n",
       "0  TRAIN_0000  블록체인 기술은 투표 과정의 투명성을 크게 향상시킬 수 있다.   \n",
       "\n",
       "                                          sentence_1  \\\n",
       "0  이러한 특성은 유권자들에게 신뢰를 제공하며, 민주적 참여를 촉진하는 데 기여할 수 있다.   \n",
       "\n",
       "                                          sentence_2  \\\n",
       "0  결과적으로 블록체인 기반의 투표 시스템은 공정하고 신뢰할 수 있는 선거 환경을 조성...   \n",
       "\n",
       "                                     sentence_3  answer_0  answer_1  answer_2  \\\n",
       "0  각 투표는 변경 불가능한 기록으로 저장되어 조작의 가능성을 원천적으로 차단한다.         0         3         1   \n",
       "\n",
       "   answer_3  \n",
       "0         2  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fbef4be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TextStreamer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0866c886",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6578d17127664e81a224ea8752264671",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device because they were offloaded to the disk.\n"
     ]
    }
   ],
   "source": [
    "model_name = 'dnotitia/Llama-DNA-1.0-8B-Instruct'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, device_map='auto', torch_dtype=torch.float32)\n",
    "#streamer = TextStreamer(tokenizer, skip_prompt=True, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0781ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_user_msg(df, idx):\n",
    "    \"\"\"\n",
    "    df: DataFrame with sentence_0 ~ sentence_3 columns\n",
    "    idx: row index to extract the 4 sentences\n",
    "    returns: formatted string with 문장 0 ~ 문장 3\n",
    "    \"\"\"\n",
    "    row = df.iloc[idx]\n",
    "    lines = [f\"문장 {i}: {row[f'sentence_{i}']}\" for i in range(4)]\n",
    "    prompt =  \"\\n\".join(lines)\n",
    "    prompt += '\\n주어진 네개의 문장 순서를 알려주세요. 아무 응답 없이 정답만 알려주세요. 정답:'\n",
    "    return prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88d7e244",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'문장 0: 블록체인 기술은 투표 과정의 투명성을 크게 향상시킬 수 있다.\\n문장 1: 이러한 특성은 유권자들에게 신뢰를 제공하며, 민주적 참여를 촉진하는 데 기여할 수 있다.\\n문장 2: 결과적으로 블록체인 기반의 투표 시스템은 공정하고 신뢰할 수 있는 선거 환경을 조성할 잠재력을 지닌다.\\n문장 3: 각 투표는 변경 불가능한 기록으로 저장되어 조작의 가능성을 원천적으로 차단한다.\\n주어진 네개의 문장 순서를 알려주세요. 아무 응답 없이 정답만 알려주세요. 정답:'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_user_msg(df, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "423e225b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 프롬프트 구성\n",
    "system_message = (\n",
    "    \"당신은 문장의 논리적 흐름을 분석하여 문장들의 올바른 순서를 맞추는 한국어 문장 전문가입니다. \"\n",
    "    \"사용자가 제시하는 4개의 문장은 순서가 섞여 있습니다. 당신의 임무는 가장 자연스러운 순서를 \"\n",
    "    \"[0, 1, 2, 3] 형식의 숫자 배열로 출력하는 것입니다.\"\n",
    "    \"문장 처음의 지시어나 접속사에 유의하여 문장 순서를 예측하세요.\"\n",
    ")\n",
    "\n",
    "# 채팅 포맷으로 구성\n",
    "conversation = [\n",
    "    {\"role\": \"system\", \"content\": system_message},\n",
    "    {\"role\": \"user\", \"content\": make_user_msg(df, 0)}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e9bab48c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [03:27<13:50, 207.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoded:\n",
      " system\n",
      "\n",
      "당신은 문장의 논리적 흐름을 분석하여 문장들의 올바른 순서를 맞추는 한국어 문장 전문가입니다. 사용자가 제시하는 4개의 문장은 순서가 섞여 있습니다. 당신의 임무는 가장 자연스러운 순서를 [0, 1, 2, 3] 형식의 숫자 배열로 출력하는 것입니다.문장 처음의 지시어나 접속사에 유의하여 문장 순서를 예측하세요.user\n",
      "\n",
      "문장 0: 블록체인 기술은 투표 과정의 투명성을 크게 향상시킬 수 있다.\n",
      "문장 1: 이러한 특성은 유권자들에게 신뢰를 제공하며, 민주적 참여를 촉진하는 데 기여할 수 있다.\n",
      "문장 2: 결과적으로 블록체인 기반의 투표 시스템은 공정하고 신뢰할 수 있는 선거 환경을 조성할 잠재력을 지닌다.\n",
      "문장 3: 각 투표는 변경 불가능한 기록으로 저장되어 조작의 가능성을 원천적으로 차단한다.\n",
      "주어진 네개의 문장 순서를 알려주세요. 아무 응답 없이 정답만 알려주세요. 정답:assistant\n",
      "\n",
      "[0, 3, 1, 2]\n",
      "Answer: [0, 3, 1, 2]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [07:04<10:38, 212.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoded:\n",
      " system\n",
      "\n",
      "당신은 문장의 논리적 흐름을 분석하여 문장들의 올바른 순서를 맞추는 한국어 문장 전문가입니다. 사용자가 제시하는 4개의 문장은 순서가 섞여 있습니다. 당신의 임무는 가장 자연스러운 순서를 [0, 1, 2, 3] 형식의 숫자 배열로 출력하는 것입니다.문장 처음의 지시어나 접속사에 유의하여 문장 순서를 예측하세요.user\n",
      "\n",
      "문장 0: 줄거리 자동 생성의 인공지능 알고리즘은 대량의 텍스트 데이터를 분석하여 핵심 정보를 추출하는 기능을 갖추고 있다.\n",
      "문장 1: 결과적으로, 이러한 기술은 사용자에게 신속하고 효율적인 정보 전달을 가능하게 한다.\n",
      "문장 2: 생성된 줄거리는 원본 텍스트의 의미를 유지하면서도 간결하게 요약된 형태로 제공된다.\n",
      "문장 3: 이 알고리즘은 자연어 처리 기술을 활용하여 문맥을 이해하고, 주요 사건과 등장인물을 식별한다.\n",
      "주어진 네개의 문장 순서를 알려주세요. 아무 응답 없이 정답만 알려주세요. 정답:assistant\n",
      "\n",
      "[3, 0, 1, 2]\n",
      "Answer: [0, 3, 2, 1]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [10:39<07:07, 213.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoded:\n",
      " system\n",
      "\n",
      "당신은 문장의 논리적 흐름을 분석하여 문장들의 올바른 순서를 맞추는 한국어 문장 전문가입니다. 사용자가 제시하는 4개의 문장은 순서가 섞여 있습니다. 당신의 임무는 가장 자연스러운 순서를 [0, 1, 2, 3] 형식의 숫자 배열로 출력하는 것입니다.문장 처음의 지시어나 접속사에 유의하여 문장 순서를 예측하세요.user\n",
      "\n",
      "문장 0: 마지막으로, 키친타올을 보관할 때는 쉽게 접근할 수 있는 곳에 두어 낭비를 방지하는 것이 중요하다.\n",
      "문장 1: 재사용 가능한 천이나 스펀지를 활용하면 키친타올의 필요성을 줄일 수 있다.\n",
      "문장 2: 물기를 제거할 때는 가볍게 눌러주어 과도한 사용을 피할 수 있다.\n",
      "문장 3: 키친타올을 절약하는 첫걸음은 필요한 양만큼만 사용하는 것이다.\n",
      "주어진 네개의 문장 순서를 알려주세요. 아무 응답 없이 정답만 알려주세요. 정답:assistant\n",
      "\n",
      "[3, 1, 2, 0]\n",
      "Answer: [3, 2, 1, 0]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [14:14<03:34, 214.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoded:\n",
      " system\n",
      "\n",
      "당신은 문장의 논리적 흐름을 분석하여 문장들의 올바른 순서를 맞추는 한국어 문장 전문가입니다. 사용자가 제시하는 4개의 문장은 순서가 섞여 있습니다. 당신의 임무는 가장 자연스러운 순서를 [0, 1, 2, 3] 형식의 숫자 배열로 출력하는 것입니다.문장 처음의 지시어나 접속사에 유의하여 문장 순서를 예측하세요.user\n",
      "\n",
      "문장 0: 책의 페이지가 손상되지 않도록 수직으로 세워 두거나 평평하게 눕혀 보관하는 것이 좋다.\n",
      "문장 1: 정기적으로 먼지를 털어내고, 곰팡이나 해충의 발생 여부를 점검하는 것이 중요하다.\n",
      "문장 2: 종이책은 직사광선이 닿지 않는 서늘하고 건조한 장소에 보관해야 한다.\n",
      "문장 3: 필요할 경우, 책을 보호하기 위해 커버를 씌우거나 전용 보관함에 넣는 방법도 고려할 수 있다.\n",
      "주어진 네개의 문장 순서를 알려주세요. 아무 응답 없이 정답만 알려주세요. 정답:assistant\n",
      "\n",
      "[0, 2, 1, 3]\n",
      "Answer: [2, 0, 1, 3]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [17:36<00:00, 211.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoded:\n",
      " system\n",
      "\n",
      "당신은 문장의 논리적 흐름을 분석하여 문장들의 올바른 순서를 맞추는 한국어 문장 전문가입니다. 사용자가 제시하는 4개의 문장은 순서가 섞여 있습니다. 당신의 임무는 가장 자연스러운 순서를 [0, 1, 2, 3] 형식의 숫자 배열로 출력하는 것입니다.문장 처음의 지시어나 접속사에 유의하여 문장 순서를 예측하세요.user\n",
      "\n",
      "문장 0: 인공지능 모델은 반복적인 실험을 통해 지속적으로 학습하며, 이를 통해 발견의 정확성을 높인다.\n",
      "문장 1: 인공지능은 대량의 데이터를 분석하여 숨겨진 패턴과 상관관계를 발견하는 데 강력한 도구가 된다.\n",
      "문장 2: 결국, 인공지능의 지원은 과학적 발견의 속도와 효율성을 혁신적으로 변화시킬 수 있는 잠재력을 지닌다.\n",
      "문장 3: 이러한 분석 결과는 연구자들에게 새로운 가설을 제시하고 실험 설계를 개선하는 데 기여할 수 있다.\n",
      "주어진 네개의 문장 순서를 알려주세요. 아무 응답 없이 정답만 알려주세요. 정답:assistant\n",
      "\n",
      "[0, 1, 2, 3]\n",
      "Answer: [1, 3, 0, 2]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 채팅 포맷으로 구성\n",
    "for i in tqdm(range(5)):\n",
    "    #print(make_user_msg(df, i))\n",
    "    conversation = [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": make_user_msg(df, i)}\n",
    "    ]   \n",
    "    inputs = tokenizer.apply_chat_template(\n",
    "        conversation,\n",
    "        add_generation_prompt=True,\n",
    "        return_dict=True,\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(model.device)\n",
    "\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=100,\n",
    "        do_sample=False,\n",
    "        temperature=1.0,\n",
    "        top_p=1.0,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        eos_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "    decoded = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    print('Decoded:\\n', decoded)\n",
    "    print('Answer:', [int(x) for x in df.iloc[i, 5:9].tolist()])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a43fab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
